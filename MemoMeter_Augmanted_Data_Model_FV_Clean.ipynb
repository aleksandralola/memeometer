{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aleksandralola/memeometer/blob/main/MemoMeter_Augmanted_Data_Model_FV_Clean.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n2nCOGx-TdVC"
      },
      "source": [
        "## Installing packages and importing libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s7Q_pzNW63AY"
      },
      "outputs": [],
      "source": [
        "# Installing required packages\n",
        "!pip install gradio pandas numpy matplotlib scikit-learn opencv-python pillow tf_keras pytesseract transformers tensorflow albumentations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qzufwR_YzpIo"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade tensorflow\n",
        "!pip install --upgrade keras\n",
        "!pip install --upgrade transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JYn2AeUH8UN2"
      },
      "outputs": [],
      "source": [
        "# Importing required libraries\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from PIL import Image\n",
        "from transformers import DistilBertTokenizer, TFDistilBertModel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Va_OlYzCzQB"
      },
      "outputs": [],
      "source": [
        "# Mounting Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6OJrkkfEC7EN"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import login\n",
        "login()  # Will prompt for token interactively if run in notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n3Q4TpXpTvIb"
      },
      "source": [
        "# Uploading data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset has been already augmented in another notebook and uploaded here after augmenting."
      ],
      "metadata": {
        "id": "86pnk2V1aphX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1vtbSwN58cAf"
      },
      "outputs": [],
      "source": [
        "# Linking dataset paths\n",
        "drive_path = '/content/drive/MyDrive/'\n",
        "dataset_path = drive_path + 'memotion_dataset_7k/labels_augmented_v2.csv'\n",
        "images_folder_path = drive_path + 'memotion_dataset_7k/images_aug/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SZuFYbAl8550"
      },
      "outputs": [],
      "source": [
        "# Loading dataset\n",
        "try:\n",
        "    df = pd.read_csv(dataset_path)\n",
        "    print(\"Dataset columns:\", df.columns.tolist())\n",
        "except Exception as e:\n",
        "    print(f\"Error loading dataset: {e}\")\n",
        "    raise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "trNCaZ1Y9All"
      },
      "outputs": [],
      "source": [
        "# Verifying image paths\n",
        "df['image_path'] = images_folder_path + df['image_name']\n",
        "print(\"\\nSample image paths:\")\n",
        "print(df['image_path'].head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KRmtfYrOWC9w"
      },
      "source": [
        "# Checking data distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cw7_d40BWH6W"
      },
      "outputs": [],
      "source": [
        "# Specifying columns to analyze\n",
        "columns_to_plot = ['humour', 'sarcasm', 'offensive', 'motivational', 'overall_sentiment']\n",
        "\n",
        "# Create subplots with 3 charts per row\n",
        "fig, axes = plt.subplots(nrows=(len(columns_to_plot) + 2) // 3, ncols=3, figsize=(15, 10))  # Adjust the figure size\n",
        "axes = axes.flatten()  # Flatten axes array for easy indexing\n",
        "\n",
        "# Calculating and plotting the distribution of values in each specified column\n",
        "for i, column in enumerate(columns_to_plot):\n",
        "    if column in df.columns:\n",
        "        value_counts = df[column].value_counts()\n",
        "\n",
        "        # Plotting the distribution on the corresponding subplot\n",
        "        value_counts.plot(kind='bar', color='skyblue', ax=axes[i])\n",
        "        axes[i].set_title(f'Distribution of values in \"{column}\"')\n",
        "        axes[i].set_xlabel('Values')\n",
        "        axes[i].set_ylabel('Frequency')\n",
        "        axes[i].tick_params(axis='x', rotation=45)\n",
        "    else:\n",
        "        print(f\"Column '{column}' not found in the dataset.\")\n",
        "        axes[i].axis('off')  # Turn off unused subplot if column is missing\n",
        "\n",
        "# Hide unused subplots if any\n",
        "for j in range(len(columns_to_plot), len(axes)):\n",
        "    axes[j].axis('off')  # Turn off unused subplots\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IzeJ9LQsT3va"
      },
      "source": [
        "# Building preprocessing functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BeFiSfkh9JpG"
      },
      "outputs": [],
      "source": [
        "# Text preprocessing function\n",
        "\n",
        "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "\n",
        "def preprocess_text(texts, max_length=128):\n",
        "    return tokenizer(\n",
        "        texts.tolist(),\n",
        "        truncation=True,\n",
        "        padding='max_length',\n",
        "        max_length=max_length,\n",
        "        return_tensors='tf'\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tTD-FY2pU1Zq"
      },
      "outputs": [],
      "source": [
        "# Image preprocessing function (with TensorFlow-native error handling)\n",
        "\n",
        "def safe_load(image_path):\n",
        "    try:\n",
        "        image = tf.io.read_file(image_path)\n",
        "        image = tf.image.decode_image(image, channels=3, expand_animations=False)\n",
        "        image = tf.image.resize(image, [224, 224])\n",
        "        image = tf.keras.applications.efficientnet.preprocess_input(image)\n",
        "        return image\n",
        "    except:\n",
        "        # Return a zero-initialized tensor of the same shape instead of None\n",
        "        return tf.zeros((224, 224, 3), dtype=tf.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GNOUsoS5WOcp"
      },
      "outputs": [],
      "source": [
        "# Ensuring image_paths and df are aligned\n",
        "valid_indices = []\n",
        "for i, image_name in enumerate(df['image_name']):\n",
        "    image_path = os.path.join(images_folder_path, image_name)\n",
        "    if os.path.exists(image_path):\n",
        "        valid_indices.append(i)\n",
        "\n",
        "# Filtering dataframe to include only valid indices\n",
        "df = df.iloc[valid_indices].reset_index(drop=True)\n",
        "\n",
        "# Rebuilding image_paths to match the filtered dataframe\n",
        "image_paths = [os.path.join(images_folder_path, name) for name in df['image_name']]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01dlqreyU8_j"
      },
      "source": [
        "# Preprocessing images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "37ltNBpcCA0l"
      },
      "outputs": [],
      "source": [
        "# Verifying TensorFlow installation\n",
        "print(\"TensorFlow version:\", tf.__version__)\n",
        "\n",
        "# Verify image directory exists\n",
        "assert os.path.exists(images_folder_path), f\"Directory {images_folder_path} not found!\"\n",
        "\n",
        "# Creating image paths and verifying them\n",
        "image_paths = [os.path.join(images_folder_path, name) for name in df['image_name']]\n",
        "\n",
        "print(\"\\nSample image paths:\")\n",
        "for path in image_paths[:5]:\n",
        "    print(f\"Exists: {os.path.exists(path)} → {path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fm9iPnXRCFI3"
      },
      "outputs": [],
      "source": [
        "# Preprocessing images\n",
        "def preprocess_image(image):\n",
        "    \"\"\"Ensure the image is RGB, even if it's grayscale\"\"\"\n",
        "    # Convert grayscale images to RGB by repeating the channels\n",
        "    if image.shape[-1] == 1:  # Grayscale image\n",
        "        image = tf.image.grayscale_to_rgb(image)\n",
        "    return image\n",
        "\n",
        "def safe_load(image_path):\n",
        "    \"\"\"Load and preprocess image with error handling\"\"\"\n",
        "    try:\n",
        "        # Read and decode image\n",
        "        image = tf.io.read_file(image_path)\n",
        "        image = tf.image.decode_image(image, channels=3, expand_animations=False)  # Decode as RGB\n",
        "        image = tf.image.resize(image, [224, 224])  # Resize to target dimensions\n",
        "        image = preprocess_image(image)  # Ensure RGB format\n",
        "        return tf.keras.applications.efficientnet.preprocess_input(image)\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading image {image_path}: {e}\")\n",
        "        return tf.zeros((224, 224, 3), dtype=tf.float32)  # Return empty image in case of error\n",
        "\n",
        "# Creating image dataset\n",
        "image_ds = tf.data.Dataset.from_tensor_slices(image_paths).map(\n",
        "    lambda path: tf.py_function(safe_load, [path], Tout=tf.float32),\n",
        "    num_parallel_calls=tf.data.AUTOTUNE\n",
        ")\n",
        "\n",
        "# Optionally suppress warnings if they're not critical\n",
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # Suppress TensorFlow warnings\n",
        "\n",
        "# Verifying the dataset\n",
        "for image in image_ds.take(1):\n",
        "    print(image.shape)  # Verify the shape of the images after preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JRe2CS6oTR0O"
      },
      "source": [
        "# Preprocessing text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NiibEt4jCZ2Q"
      },
      "outputs": [],
      "source": [
        "# Removing rows with NaN or empty strings in 'text_corrected'\n",
        "df = df.dropna(subset=['text_corrected'])\n",
        "df = df[df['text_corrected'] != \"\"]\n",
        "\n",
        "# Converting all entries to strings (in case of numeric/None values)\n",
        "df['text_corrected'] = df['text_corrected'].astype(str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vo5SRBvjCKqg"
      },
      "outputs": [],
      "source": [
        "# Preprocessing text\n",
        "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "\n",
        "def preprocess_text(texts, max_length=128):\n",
        "    return tokenizer(\n",
        "        texts.tolist(),\n",
        "        truncation=True,\n",
        "        padding='max_length',\n",
        "        max_length=max_length,\n",
        "        return_tensors='tf'\n",
        "    )\n",
        "\n",
        "# Tokenizing text\n",
        "tokenized_texts = preprocess_text(df['text_corrected'])\n",
        "\n",
        "# Creating text dataset\n",
        "text_ds = tf.data.Dataset.from_tensor_slices({\n",
        "    'input_ids': tokenized_texts['input_ids'],\n",
        "    'attention_mask': tokenized_texts['attention_mask']\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iUe9p910bhMk"
      },
      "outputs": [],
      "source": [
        "# Veryfying images vs text and removing not matching ones\n",
        "extra_images = []\n",
        "for image_path in image_paths:\n",
        "    image_name = os.path.basename(image_path)\n",
        "    if image_name not in df['image_name'].values:\n",
        "        extra_images.append(image_path)\n",
        "\n",
        "filtered_image_paths = [path for path in image_paths if path not in extra_images]\n",
        "image_paths = filtered_image_paths\n",
        "\n",
        "# Verifying alignment\n",
        "print(f\"Final image dataset size: {len(image_paths)}\")\n",
        "print(f\"Text dataset size: {len(df)}\")\n",
        "assert len(image_paths) == len(df), \"Mismatch resolved!\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kSLXJsmHCnWC"
      },
      "source": [
        "# Creating label dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wcaLzp_DCNjE"
      },
      "outputs": [],
      "source": [
        "# Defining mappings for categorical columns\n",
        "humour_mapping = {'not_funny': 0, 'funny': 1, 'very_funny': 2, 'hilarious': 3}\n",
        "sarcasm_mapping = {'not_sarcastic': 0, 'general': 1, 'twisted_meaning': 2,}\n",
        "offensive_mapping = {'not_offensive': 0, 'slight_offensive':1, 'very_offensive':2,}\n",
        "motivational_mapping = {'not_motivational': 0, 'motivational': 1}\n",
        "overall_sentiment_mapping = {'negative': 0, 'neutral': 1, 'positive': 2, 'very_positive': 3}\n",
        "\n",
        "# Replaceing string values with numerical equivalents using the mappings\n",
        "# Filling NaN values with a default category (e.g., 'not_sarcastic' for sarcasm)\n",
        "df['humour'] = df['humour'].map(humour_mapping).fillna(0).astype(int)\n",
        "df['sarcasm'] = df['sarcasm'].map(sarcasm_mapping).fillna(0).astype(int)\n",
        "df['offensive'] = df['offensive'].map(offensive_mapping).fillna(0).astype(int)\n",
        "df['motivational'] = df['motivational'].map(motivational_mapping).fillna(0).astype(int)\n",
        "df['overall_sentiment'] = df['overall_sentiment'].map(overall_sentiment_mapping).fillna(0).astype(int)\n",
        "\n",
        "# Creating the labels dataset with the mapped numerical values\n",
        "labels_ds = tf.data.Dataset.from_tensor_slices({\n",
        "    'humour': df['humour'].values,\n",
        "    'sarcasm': df['sarcasm'].values,\n",
        "    'offensive': df['offensive'].values,\n",
        "    'motivational': df['motivational'].values,\n",
        "    'overall_sentiment':df['overall_sentiment'].values\n",
        "})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DqmkXbJoCwHg"
      },
      "source": [
        "# Combining datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ft74Jw91CjNR"
      },
      "outputs": [],
      "source": [
        "def ensure_shapes(example_inputs, example_labels):\n",
        "    example_inputs['image_input'] = tf.ensure_shape(example_inputs['image_input'], [224, 224, 3])\n",
        "    return example_inputs, example_labels\n",
        "\n",
        "# Combining image, text and label datasets\n",
        "full_ds = tf.data.Dataset.zip((text_ds, image_ds, labels_ds)).map(\n",
        "    lambda text, img, labels: (\n",
        "        {'input_ids': text['input_ids'], 'attention_mask': text['attention_mask'], 'image_input': img},\n",
        "        {'humour': labels['humour'], 'sarcasm': labels['sarcasm'], 'offensive': labels['offensive'], 'motivational': labels['motivational'], 'overall_sentiment': labels['overall_sentiment']}\n",
        "    )\n",
        ").map(ensure_shapes)  # Applying the ensure_shapes function to fix image input shapes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85mE628TFdEY"
      },
      "source": [
        "# Shuffle and split the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yNmgmh1zFUe7"
      },
      "outputs": [],
      "source": [
        "# Shuffling datasets and splitting into train, validate, and test parts\n",
        "dataset_size = len(df)\n",
        "train_size = int(0.8 * dataset_size)\n",
        "val_size = int(0.1 * dataset_size)\n",
        "\n",
        "buffer_size = 9000  # Adjust this value as needed\n",
        "\n",
        "full_ds = full_ds.shuffle(buffer_size=buffer_size)\n",
        "train_ds = full_ds.take(train_size)\n",
        "remaining = full_ds.skip(train_size)\n",
        "val_ds = remaining.take(val_size)\n",
        "test_ds = remaining.skip(val_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uMKVmV8eFlN-"
      },
      "source": [
        "# Batch and optimize the datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7FyBY7xeCtV0"
      },
      "outputs": [],
      "source": [
        "# Batching the dataset and optimising\n",
        "BATCH_SIZE = 64\n",
        "train_ds = train_ds.cache().batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "val_ds = val_ds.cache().batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "test_ds = test_ds.batch(BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-5NWirjFtBi"
      },
      "source": [
        "# Verifying batch structure\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aSd-wqthFnL0"
      },
      "outputs": [],
      "source": [
        "# Verifying batch structure\n",
        "for batch in train_ds.take(1):\n",
        "    inputs, labels = batch\n",
        "    print(\"Input IDs shape:\", inputs['input_ids'].shape)  # (8, 128)\n",
        "    print(\"Image shape:\", inputs['image_input'].shape)    # (8, 224, 224, 3)\n",
        "    print(\"Humour labels shape:\", labels['humour'].shape)   # (8,)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DFfvstcFYtKC"
      },
      "source": [
        "# Building the model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, Model, regularizers\n",
        "from transformers import TFDistilBertModel\n",
        "\n",
        "# Defining constants\n",
        "TEXT_SEQ_LENGTH = 128\n",
        "IMAGE_SIZE = 224\n",
        "\n",
        "# Custom DistilBERT wrapper\n",
        "class DistilBertEncoder(tf.keras.layers.Layer):\n",
        "    def __init__(self, model_name='distilbert-base-uncased', **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.bert = TFDistilBertModel.from_pretrained(model_name)\n",
        "        self.bert.trainable = False  # Set to True to fine-tune\n",
        "\n",
        "    def call(self, inputs):\n",
        "        input_ids, attention_mask = inputs\n",
        "        output = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        return output.last_hidden_state[:, 0, :]  # [CLS] token\n"
      ],
      "metadata": {
        "id": "mF8EP-LqbGIF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Text Input\n",
        "input_ids = layers.Input(shape=(TEXT_SEQ_LENGTH,), dtype=tf.int32, name='input_ids')\n",
        "attention_mask = layers.Input(shape=(TEXT_SEQ_LENGTH,), dtype=tf.int32, name='attention_mask')\n",
        "text_features = DistilBertEncoder()([input_ids, attention_mask])\n",
        "\n",
        "# Image Input\n",
        "image_input = layers.Input(shape=(IMAGE_SIZE, IMAGE_SIZE, 3), name='image_input')\n",
        "base_model = tf.keras.applications.EfficientNetB0(\n",
        "    include_top=False,\n",
        "    weights='imagenet',\n",
        "    input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3)\n",
        ")\n",
        "base_model.trainable = False\n",
        "image_features = layers.GlobalAveragePooling2D()(base_model(image_input))\n",
        "\n",
        "# Combining inputs\n",
        "combined = layers.Concatenate()([text_features, image_features])\n",
        "x = layers.Dense(256, activation='relu', kernel_regularizer=regularizers.l2(0.01))(combined)\n",
        "x = layers.BatchNormalization()(x)\n",
        "# 👇 No dropout here\n",
        "\n",
        "# Defining outputs\n",
        "outputs = {\n",
        "    'humour': layers.Dense(4, activation='softmax', name='humour')(x),\n",
        "    'sarcasm': layers.Dense(3, activation='softmax', name='sarcasm')(x),\n",
        "    'offensive': layers.Dense(3, activation='softmax', name='offensive')(x),\n",
        "    'motivational': layers.Dense(2, activation='softmax', name='motivational')(x),\n",
        "    'overall_sentiment': layers.Dense(4, activation='softmax', name='overall_sentiment')(x)\n",
        "}\n",
        "\n",
        "# Final model\n",
        "model = Model(inputs=[input_ids, attention_mask, image_input], outputs=outputs)"
      ],
      "metadata": {
        "id": "NXZ8T_zGbPKs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8gEEF1y5ZJN9"
      },
      "outputs": [],
      "source": [
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss={\n",
        "        'humour': 'sparse_categorical_crossentropy',\n",
        "        'sarcasm': 'sparse_categorical_crossentropy',\n",
        "        'offensive': 'sparse_categorical_crossentropy',\n",
        "        'motivational': 'sparse_categorical_crossentropy',\n",
        "        'overall_sentiment': 'sparse_categorical_crossentropy'\n",
        "    },\n",
        "    metrics={\n",
        "        'humour': 'accuracy',\n",
        "        'sarcasm': 'accuracy',\n",
        "        'offensive': 'accuracy',\n",
        "        'motivational': 'accuracy',\n",
        "        'overall_sentiment': 'accuracy'\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G3wnco8dGNem"
      },
      "source": [
        "# Training and saving the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WVwOgbrzmqzU"
      },
      "outputs": [],
      "source": [
        "# Training the model with basic settings and 8 epochs\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=8\n",
        ")\n",
        "\n",
        "# Saving the entire model\n",
        "model.save(\"/content/drive/MyDrive/AI_Models/meme_final_model_aug.keras\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluating the model with confusion matrix"
      ],
      "metadata": {
        "id": "3Wt_pY1d_P5G"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ro6q5xpLWloW"
      },
      "outputs": [],
      "source": [
        "# Getting true labels and predicted labels\n",
        "y_true = {label: [] for label in ['humour', 'sarcasm', 'offensive', 'motivational', 'overall_sentiment']}\n",
        "y_pred = {label: [] for label in ['humour', 'sarcasm', 'offensive', 'motivational', 'overall_sentiment']}\n",
        "\n",
        "label_names = ['humour', 'sarcasm', 'offensive', 'motivational', 'overall_sentiment']\n",
        "\n",
        "for images, labels in test_ds:\n",
        "    preds = model.predict(images)\n",
        "    # Access labels and predictions using keys instead of indices\n",
        "    for label_name in label_names:\n",
        "        y_true[label_name].extend(labels[label_name].numpy())\n",
        "        # Access predictions using the label name directly\n",
        "        y_pred[label_name].extend(np.argmax(preds[label_name], axis=1))\n",
        "\n",
        "# Evaluating each class\n",
        "for label in label_names:\n",
        "    print(f\"--- {label.upper()} ---\")\n",
        "    print(classification_report(y_true[label], y_pred[label]))\n",
        "\n",
        "    cm = confusion_matrix(y_true[label], y_pred[label])\n",
        "    plt.figure(figsize=(4, 3))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "    plt.title(f'{label.capitalize()} Confusion Matrix')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('True')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation metrics without the confusion matrix\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "\n",
        "# Getting true labels and predicted labels\n",
        "y_true = {label: [] for label in ['humour', 'sarcasm', 'offensive', 'motivational', 'overall_sentiment']}\n",
        "y_pred = {label: [] for label in ['humour', 'sarcasm', 'offensive', 'motivational', 'overall_sentiment']}\n",
        "\n",
        "label_names = ['humour', 'sarcasm', 'offensive', 'motivational', 'overall_sentiment']\n",
        "\n",
        "for images, labels in test_ds:\n",
        "    preds = model.predict(images)\n",
        "    for label_name in label_names:\n",
        "        y_true[label_name].extend(labels[label_name].numpy())\n",
        "        y_pred[label_name].extend(np.argmax(preds[label_name], axis=1))\n",
        "\n",
        "# Evaluating each class and printing metrics\n",
        "for label in label_names:\n",
        "    print(f\"--- {label.upper()} ---\")\n",
        "    print(classification_report(y_true[label], y_pred[label], digits=4))\n",
        "    print(\"\\n\" + \"=\"*50 + \"\\n\")"
      ],
      "metadata": {
        "id": "JVbwk7_upCsO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving the entire model again (just in case :)\n",
        "model.save(\"/content/drive/MyDrive/AI_Models/meme_final_model_aug3.keras\")"
      ],
      "metadata": {
        "id": "HTKXRbt-3e0d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gEtuz8rdfurb"
      },
      "source": [
        "# Gradio Prototyping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_mtqhnWTf1xw"
      },
      "outputs": [],
      "source": [
        "!pip install gradio pytesseract"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nxjct8actjkV"
      },
      "outputs": [],
      "source": [
        "# Installing Tesseract-OCR\n",
        "!sudo apt-get update\n",
        "!sudo apt-get install -y tesseract-ocr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UyDRZl38txY-"
      },
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "import pytesseract\n",
        "from PIL import Image\n",
        "\n",
        "pytesseract.pytesseract.tesseract_cmd = r'/usr/bin/tesseract'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AFHZhNbwt8O_"
      },
      "outputs": [],
      "source": [
        "# Testing OCR with a sample image\n",
        "def test_ocr():\n",
        "    img = Image.open(\"/content/drive/MyDrive/memotion_dataset_7k/images/image_333.jpg\")\n",
        "    text = pytesseract.image_to_string(img)\n",
        "    print(\"Extracted Text:\", text)\n",
        "\n",
        "test_ocr()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from transformers import DistilBertTokenizer\n",
        "from PIL import Image\n",
        "import pytesseract\n",
        "import gradio as gr\n",
        "\n",
        "# Loading tokenizer\n",
        "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "\n",
        "# Classifying labels\n",
        "class_names = {\n",
        "    'humour': ['😐 Not Funny', '🙂 Funny', '😆 Very Funny', '🤣 Hilarious'],\n",
        "    'sarcasm': ['🧐 Not Sarcastic', '😏 General Sarcasm', '🤨 Twisted Meaning'],\n",
        "    'offensive': ['✅ Not Offensive', '⚠️ Slightly Offensive', '🚫 Offensive'],\n",
        "    'motivational': ['🙃 Not Motivational', '💡 Motivational'],\n",
        "    'overall_sentiment': ['🙁 Negative', '😐 Neutral', '🙂 Positive', '🌟 Very Positive']\n",
        "}\n",
        "\n",
        "# OCR function\n",
        "def extract_text_from_image(img):\n",
        "    try:\n",
        "        gray_img = img.convert('L')\n",
        "        text = pytesseract.image_to_string(gray_img)\n",
        "        return text.strip()\n",
        "    except Exception as e:\n",
        "        return f\"OCR Error: {str(e)}\"\n",
        "\n",
        "# Text preprocessing\n",
        "def preprocess_text(text):\n",
        "    return tokenizer(\n",
        "        text,\n",
        "        truncation=True,\n",
        "        padding='max_length',\n",
        "        max_length=128,\n",
        "        return_tensors='tf'\n",
        "    )\n",
        "\n",
        "# Main prediction function\n",
        "def predict_meme(input_image, user_text=None):\n",
        "    try:\n",
        "        image_text = extract_text_from_image(input_image)\n",
        "        full_text = f\"{image_text} {user_text}\" if user_text else image_text\n",
        "\n",
        "        img = input_image.resize((224, 224))\n",
        "        img_array = np.array(img) / 255.0\n",
        "        if img_array.shape[-1] != 3:\n",
        "            img_array = img_array[..., :3]\n",
        "        img_array = img_array.reshape(1, 224, 224, 3)\n",
        "\n",
        "        text_encoded = preprocess_text([full_text])\n",
        "\n",
        "        predictions = model.predict([\n",
        "            text_encoded['input_ids'],\n",
        "            text_encoded['attention_mask'],\n",
        "            img_array\n",
        "        ])\n",
        "\n",
        "        # Use correct unpacking\n",
        "        humour_pred = predictions['humour']\n",
        "        sarcasm_pred = predictions['sarcasm']\n",
        "        offensive_pred = predictions['offensive']\n",
        "        motivational_pred = predictions['motivational']\n",
        "        overall_sentiment_pred = predictions['overall_sentiment']\n",
        "\n",
        "        # Debug print\n",
        "        print(\"Humour prediction:\", humour_pred)\n",
        "        print(\"Sarcasm prediction:\", sarcasm_pred)\n",
        "        print(\"Offensive prediction:\", offensive_pred)\n",
        "        print(\"Motivational prediction:\", motivational_pred)\n",
        "        print(\"Overall sentiment prediction:\", overall_sentiment_pred)\n",
        "\n",
        "        # Get highest-probability index for each\n",
        "        humour_idx = np.argmax(humour_pred[0])\n",
        "        sarcasm_idx = np.argmax(sarcasm_pred[0])\n",
        "        offensive_idx = np.argmax(offensive_pred[0])\n",
        "        motivational_idx = np.argmax(motivational_pred[0])\n",
        "        overall_sentiment_idx = np.argmax(overall_sentiment_pred[0])\n",
        "\n",
        "        return (\n",
        "            class_names['humour'][humour_idx],\n",
        "            class_names['sarcasm'][sarcasm_idx],\n",
        "            class_names['offensive'][offensive_idx],\n",
        "            class_names['motivational'][motivational_idx],\n",
        "            class_names['overall_sentiment'][overall_sentiment_idx]\n",
        "        )\n",
        "\n",
        "    except Exception as e:\n",
        "        return str(e), \"\", \"\", \"\", \"\"\n",
        "\n",
        "# Gradio UI\n",
        "iface = gr.Interface(\n",
        "    fn=predict_meme,\n",
        "    inputs=[\n",
        "        gr.Image(type=\"pil\", label=\"Upload Meme Image\")\n",
        "    ],\n",
        "    outputs=[\n",
        "        gr.Label(label=\"Humour\"),\n",
        "        gr.Label(label=\"Sarcasm\"),\n",
        "        gr.Label(label=\"Offensive\"),\n",
        "        gr.Label(label=\"Motivational\"),\n",
        "        gr.Label(label=\"Overall Sentiment\")\n",
        "    ],\n",
        "    title=\"🧠 Meme-o-Meter: AI Sentiment Classifier for Memes\",\n",
        "    description=\"Upload a meme and receive predictions across 5 emotional dimensions.\"\n",
        ")\n",
        "\n",
        "iface.launch(share=True)\n"
      ],
      "metadata": {
        "id": "rLeyEre7xcSv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yG7KABMFw4w7"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}